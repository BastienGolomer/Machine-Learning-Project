{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a309f408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import loading as ld\n",
    "import implementations as imp\n",
    "import confusion_matrix as conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0b4574c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data using our own method\n",
    "y, X, ids = ld.load_csv_data('/Users/arthurbrousse/Documents/GitHub/Machine-Learning-Project/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "200ff600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DER_mass_MMC', 'DER_mass_transverse_met_lep', 'DER_mass_vis',\n",
       "       'DER_pt_h', 'DER_deltaeta_jet_jet', 'DER_mass_jet_jet',\n",
       "       'DER_prodeta_jet_jet', 'DER_deltar_tau_lep', 'DER_pt_tot',\n",
       "       'DER_sum_pt', 'DER_pt_ratio_lep_tau', 'DER_met_phi_centrality',\n",
       "       'DER_lep_eta_centrality', 'PRI_tau_pt', 'PRI_tau_eta',\n",
       "       'PRI_tau_phi', 'PRI_lep_pt', 'PRI_lep_eta', 'PRI_lep_phi',\n",
       "       'PRI_met', 'PRI_met_phi', 'PRI_met_sumet', 'PRI_jet_num',\n",
       "       'PRI_jet_leading_pt', 'PRI_jet_leading_eta', 'PRI_jet_leading_phi',\n",
       "       'PRI_jet_subleading_pt', 'PRI_jet_subleading_eta',\n",
       "       'PRI_jet_subleading_phi', 'PRI_jet_all_pt'], dtype='<U27')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.delete(ids,[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca746ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"PRI_jet_num_0 = new_X[:][new_X[:,22] == 0 ]\\nnew_PRI_jet_num_0 = PRI_jet_num_0.copy()\\nnew_PRI_jet_num_0 = np.delete(new_PRI_jet_num_0, np.where(new_PRI_jet_num_0 == -999)[1], axis=1)\\n\\nPRI_jet_num_1 = new_X[1:][new_X[1:,22] == 1]\\nnew_PRI_jet_num_1 = PRI_jet_num_1.copy()\\nnew_PRI_jet_num_1 = np.delete(new_PRI_jet_num_1, np.where(new_PRI_jet_num_1 == -999)[1], axis=1)\\n\\nPRI_jet_num_2 = new_X[1:][new_X[1:,22] == 2]\\nnew_PRI_jet_num_2 = PRI_jet_num_2.copy()\\nnew_PRI_jet_num_2 = np.delete(new_PRI_jet_num_2, np.where(new_PRI_jet_num_2 == -999)[1], axis=1)\\n\\nPRI_jet_num_3 = new_X[1:][new_X[1:,22] == 3]\\nnew_PRI_jet_num_3 = PRI_jet_num_3.copy()\\nnew_PRI_jet_num_3 = np.delete(new_PRI_jet_num_3, np.where(new_PRI_jet_num_3 == -999)[1], axis=1)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data processing : getting rid of the columns which have \"-999\" values\n",
    "new_X = X.copy()\n",
    "new_X = np.delete(new_X, np.where(new_X == -999)[1], axis=1)\n",
    "\n",
    "# the variable PRI_jet_num seems quite central, as many other variables depend on it\n",
    "# here the data is separated following this fact\n",
    "\"\"\"\"PRI_jet_num_0 = new_X[:][new_X[:,22] == 0 ]\n",
    "new_PRI_jet_num_0 = PRI_jet_num_0.copy()\n",
    "new_PRI_jet_num_0 = np.delete(new_PRI_jet_num_0, np.where(new_PRI_jet_num_0 == -999)[1], axis=1)\n",
    "\n",
    "PRI_jet_num_1 = new_X[1:][new_X[1:,22] == 1]\n",
    "new_PRI_jet_num_1 = PRI_jet_num_1.copy()\n",
    "new_PRI_jet_num_1 = np.delete(new_PRI_jet_num_1, np.where(new_PRI_jet_num_1 == -999)[1], axis=1)\n",
    "\n",
    "PRI_jet_num_2 = new_X[1:][new_X[1:,22] == 2]\n",
    "new_PRI_jet_num_2 = PRI_jet_num_2.copy()\n",
    "new_PRI_jet_num_2 = np.delete(new_PRI_jet_num_2, np.where(new_PRI_jet_num_2 == -999)[1], axis=1)\n",
    "\n",
    "PRI_jet_num_3 = new_X[1:][new_X[1:,22] == 3]\n",
    "new_PRI_jet_num_3 = PRI_jet_num_3.copy()\n",
    "new_PRI_jet_num_3 = np.delete(new_PRI_jet_num_3, np.where(new_PRI_jet_num_3 == -999)[1], axis=1)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93068a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[144603.,  19730.],\n",
       "       [ 44040.,  41627.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wls=imp.least_squares(y,X)\n",
    "ychapo=X.dot(wls[0])\n",
    "for i in range (0,len(ychapo)):\n",
    "    if ychapo[i]>0.5:\n",
    "        ychapo[i]=int(1)\n",
    "    else:\n",
    "         ychapo[i]=int(0)\n",
    "conf.compute_confusion_matrix(y,ychapo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5675ec7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[164333.,      0.],\n",
       "       [ 85667.,      0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wlsgd=imp.least_square_GD(y,X,np.ones(30),100,0.8)\n",
    "ychap=X.dot(wlsgd[0])\n",
    "for i in range (0,len(ychap)):\n",
    "    if ychap[i]>0.5:\n",
    "        ychap[i]=int(1)\n",
    "    else:\n",
    "         ychap[i]=int(0)\n",
    "conf.compute_confusion_matrix(y,ychap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2836b846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[164333.,      0.],\n",
       "       [ 85667.,      0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wls=imp.least_squares_SGD(y,X,np.ones(30),100,0.3)\n",
    "ychapo=X.dot(wls[0])\n",
    "for i in range (0,len(ychapo)):\n",
    "    if ychapo[i]>0.5:\n",
    "        ychapo[i]=int(1)\n",
    "    else:\n",
    "         ychapo[i]=int(0)\n",
    "conf.compute_confusion_matrix(y,ychapo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "188a688d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[149237.,  15096.],\n",
       "       [ 50867.,  34800.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wls=imp.ridge_regression(y,X,0.5)\n",
    "ychapo=X.dot(wls[0])\n",
    "for i in range (0,len(ychapo)):\n",
    "    if ychapo[i]>0.5:\n",
    "        ychapo[i]=int(1)\n",
    "    else:\n",
    "         ychapo[i]=int(0)\n",
    "conf.compute_confusion_matrix(y,ychapo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e44ade41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arthurbrousse/Documents/GitHub/Machine-Learning-Project/Project 1/loss_functions.py:5: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1 + np.exp(-x))\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'lambda_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-dfa75252e59a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mychapo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mychapo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mychapo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mychapo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/Machine-Learning-Project/Project 1/implementations.py\u001b[0m in \u001b[0;36mlogistic_regression\u001b[0;34m(y, tx, initial_w, max_iters, gamma)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m# Logistic regression using gradient descent or SGD :\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlogistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mleast_squares_SGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_gradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# Regularized logistic regression using gradient descent or SGD :\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/Machine-Learning-Project/Project 1/implementations.py\u001b[0m in \u001b[0;36mleast_squares_SGD\u001b[0;34m(y, tx, initial_w, max_iters, gamma, loss_function, gradient)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0myn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# compute gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;31m# compute and update y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/Machine-Learning-Project/Project 1/grad_functions.py\u001b[0m in \u001b[0;36mlog_gradient\u001b[0;34m(y, tx, w)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlog_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lambda_' is not defined"
     ]
    }
   ],
   "source": [
    "wls=imp.logistic_regression(y,X,np.ones(30),100,0.1)\n",
    "ychapo=X.dot(wls[0])\n",
    "for i in range (0,len(ychapo)):\n",
    "    if ychapo[i]>0.5:\n",
    "        ychapo[i]=int(1)\n",
    "    else:\n",
    "         ychapo[i]=int(0)\n",
    "conf.compute_confusion_matrix(y,ychapo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d951d566",
   "metadata": {},
   "outputs": [],
   "source": [
    "wls=imp.reg_logistic_regression(y,X,0.1,np.ones(30),100,0.1)\n",
    "ychapo=X.dot(wls[0])\n",
    "for i in range (0,len(ychapo)):\n",
    "    if ychapo[i]>0.5:\n",
    "        ychapo[i]=int(1)\n",
    "    else:\n",
    "         ychapo[i]=int(0)\n",
    "conf.compute_confusion_matrix(y,ychapo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f465f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the train.csv into a training set and a validation set\n",
    "X_train, X_validate = np.split(X,[int(.5*len(X))])\n",
    "y_train, y_validate = np.split(y,[int(.5*len(y))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2fdb4a",
   "metadata": {},
   "source": [
    "for the graph there needs to be no extra modifications to the csv file after it is read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a539df",
   "metadata": {},
   "outputs": [],
   "source": [
    "vecto=[]\n",
    "[vecto.append(random.randrange(1,250000,1)) for i in range (1,1000)]\n",
    "for i in range (2,16):\n",
    "    plt.figure(i)\n",
    "    plt.scatter(train[vecto,i],train[vecto,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3a763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vecto=[]\n",
    "[vecto.append(random.randrange(250000)) for i in range (1,1000)]\n",
    "for i in range (17,32):\n",
    "    plt.figure(i)\n",
    "    plt.scatter(train[vecto,i],train[vecto,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e979f9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainb=[]\n",
    "trains=[]\n",
    "for i in train[1:250000,:]:\n",
    "    if i[1]==\"b\":\n",
    "        trainb.append(i)\n",
    "    else:\n",
    "        trains.append(i)\n",
    "trains=np.asarray(trains)\n",
    "trainb=np.asarray(trainb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab7ffda",
   "metadata": {},
   "outputs": [],
   "source": [
    "vecto=[]\n",
    "vect=[]\n",
    "[vecto.append(random.randrange(len(trainb))) for i in range (1,500)]\n",
    "[vect.append(random.randrange(len(trains))) for i in range (1,500)]\n",
    "print(len(vect),len(trains))\n",
    "for i in range (2,5):\n",
    "    for j in range (2,5):\n",
    "        plt.figure(i+j)\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.scatter(trainb[vecto,i],trainb[vecto,j],color='blue')\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.scatter(trains[vect,i],trains[vect,j],color='red')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ff1774c64d83fce3825259fa3771bbe70271854497325f5fa1e2c1b92279703"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
